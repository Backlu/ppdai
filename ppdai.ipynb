{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PPDAI Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jayhsu/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ppdaiutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'TRAIN_PATH':'data/train.csv',\n",
    "    'TEST_PATH':'data/test.csv',\n",
    "    'QUESTION_PATH' : 'data/question.csv',   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** read data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load files...\n"
     ]
    }
   ],
   "source": [
    "print('Load files...')\n",
    "data={\n",
    "    'qes' : pd.read_csv(config['QUESTION_PATH']),\n",
    "    'tr' : pd.read_csv(config['TRAIN_PATH']),\n",
    "    'te' : pd.read_csv(config['TEST_PATH']),\n",
    "    #'co' : questions['words'],\n",
    "}\n",
    "data['co']=data['qes']['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    display(data['qes'].head())\n",
    "    display(data['tr'].head())\n",
    "    display(data['te'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ID轉成詞語序列or單字序列**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get texts/chars...\n"
     ]
    }
   ],
   "source": [
    "def get_ids(qids):\n",
    "    ids = []\n",
    "    for t_ in qids:\n",
    "        ids.append(int(t_[1:]))\n",
    "    return np.asarray(ids)\n",
    "\n",
    "def get_textschars(d):\n",
    "    all_words = data['qes']['words']\n",
    "    all_chars = data['qes']['chars']\n",
    "    q1id, q2id = d['q1'], d['q2']\n",
    "    id1s, id2s = get_ids(q1id), get_ids(q2id)\n",
    "    q1_texts = []\n",
    "    q2_texts = []\n",
    "    for t_ in zip(id1s, id2s):\n",
    "        q1_texts.append(all_words[t_[0]])\n",
    "        q2_texts.append(all_words[t_[1]])\n",
    "    d['q1_texts'] = q1_texts\n",
    "    d['q2_texts'] = q2_texts\n",
    "    \n",
    "    q1_chars = []\n",
    "    q2_chars = []\n",
    "    for t_ in zip(id1s, id2s):\n",
    "        q1_chars.append(all_chars[t_[0]])\n",
    "        q2_chars.append(all_chars[t_[1]])\n",
    "    d['q1_chars'] = q1_chars\n",
    "    d['q2_chars'] = q2_chars\n",
    "    \n",
    "\n",
    "print('Get texts/chars...')\n",
    "get_textschars(data['tr'])\n",
    "get_textschars(data['te'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q1_texts</th>\n",
       "      <th>q2_texts</th>\n",
       "      <th>q1_chars</th>\n",
       "      <th>q2_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Q397345</td>\n",
       "      <td>Q538594</td>\n",
       "      <td>W04465 W04058 W05284 W02916</td>\n",
       "      <td>W18238 W18843 W01490 W09905</td>\n",
       "      <td>L2218 L2568 L0360 L0242 L2218 L0741</td>\n",
       "      <td>L3019 L0104 L0582 L2218 L1861 L1556 L0242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Q193805</td>\n",
       "      <td>Q699273</td>\n",
       "      <td>W10054 W04476 W09996 W12244 W18103</td>\n",
       "      <td>W18439 W00863 W04259 W00740 W16070</td>\n",
       "      <td>L2376 L2168 L0050 L1187 L0104 L2432 L0902 L014...</td>\n",
       "      <td>L0156 L2452 L1187 L0104 L2459 L2979 L2613 L0449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Q085471</td>\n",
       "      <td>Q676160</td>\n",
       "      <td>W04346 W17378 W19355 W17926 W14185 W11567 W07863</td>\n",
       "      <td>W14586 W09745 W06017 W09067 W16319</td>\n",
       "      <td>L2323 L1526 L2214 L1132 L2723 L1861 L2249 L050...</td>\n",
       "      <td>L2568 L0971 L1291 L0358 L0037 L2582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Q189314</td>\n",
       "      <td>Q438123</td>\n",
       "      <td>W17508 W09996 W19662 W17534 W11399 W17057 W182...</td>\n",
       "      <td>W18238 W02357 W06606</td>\n",
       "      <td>L0018 L2321 L1346 L2432 L0902 L1149 L1980 L187...</td>\n",
       "      <td>L3019 L0104 L1104 L1935 L1683 L2495 L2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Q267714</td>\n",
       "      <td>Q290126</td>\n",
       "      <td>W13157 W03390 W01952 W05789 W17378 W08714 W13157</td>\n",
       "      <td>W04476 W06606 W00316 W13157</td>\n",
       "      <td>L2271 L1346 L1389 L2932 L0466 L2218 L1971 L221...</td>\n",
       "      <td>L0050 L1187 L0104 L1683 L2495 L2812 L1588 L255...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label       q1       q2                                           q1_texts  \\\n",
       "0      1  Q397345  Q538594                        W04465 W04058 W05284 W02916   \n",
       "1      0  Q193805  Q699273                 W10054 W04476 W09996 W12244 W18103   \n",
       "2      0  Q085471  Q676160   W04346 W17378 W19355 W17926 W14185 W11567 W07863   \n",
       "3      0  Q189314  Q438123  W17508 W09996 W19662 W17534 W11399 W17057 W182...   \n",
       "4      0  Q267714  Q290126   W13157 W03390 W01952 W05789 W17378 W08714 W13157   \n",
       "\n",
       "                             q2_texts  \\\n",
       "0         W18238 W18843 W01490 W09905   \n",
       "1  W18439 W00863 W04259 W00740 W16070   \n",
       "2  W14586 W09745 W06017 W09067 W16319   \n",
       "3                W18238 W02357 W06606   \n",
       "4         W04476 W06606 W00316 W13157   \n",
       "\n",
       "                                            q1_chars  \\\n",
       "0                L2218 L2568 L0360 L0242 L2218 L0741   \n",
       "1  L2376 L2168 L0050 L1187 L0104 L2432 L0902 L014...   \n",
       "2  L2323 L1526 L2214 L1132 L2723 L1861 L2249 L050...   \n",
       "3  L0018 L2321 L1346 L2432 L0902 L1149 L1980 L187...   \n",
       "4  L2271 L1346 L1389 L2932 L0466 L2218 L1971 L221...   \n",
       "\n",
       "                                            q2_chars  \n",
       "0          L3019 L0104 L0582 L2218 L1861 L1556 L0242  \n",
       "1    L0156 L2452 L1187 L0104 L2459 L2979 L2613 L0449  \n",
       "2                L2568 L0971 L1291 L0358 L0037 L2582  \n",
       "3          L3019 L0104 L1104 L1935 L1683 L2495 L2812  \n",
       "4  L0050 L1187 L0104 L1683 L2495 L2812 L1588 L255...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tr'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 序列化**\n",
    "- tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data/word_embed.txt') as f:\n",
    "    MAX_NB_WORDS = (len(list(f)))\n",
    "\n",
    "trq1_text=data['tr']['q1_texts'].values\n",
    "trq2_text=data['tr']['q2_texts'].values\n",
    "teq1_text=data['te']['q1_texts'].values\n",
    "teq2_text=data['te']['q2_texts'].values\n",
    "alltext=np.concatenate([trq1_text, trq2_text, teq1_text, teq2_text])\n",
    "MAX_SEQUENCE_LENGTH = max(list(map(lambda x: len(x), alltext))) \n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS) \n",
    "tokenizer.fit_on_texts(alltext) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tr']['q1_sequences'] = tokenizer.texts_to_sequences(trq1_text) \n",
    "data['tr']['q2_sequences'] = tokenizer.texts_to_sequences(trq2_text) \n",
    "data['te']['q1_sequences'] = tokenizer.texts_to_sequences(teq1_text) \n",
    "data['te']['q2_sequences'] = tokenizer.texts_to_sequences(teq2_text) \n",
    "#data['tr'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15880 unique tokens\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index \n",
    "print('Found %s unique tokens' % len(word_index)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3. pad_sequences **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['trq1_padseq'] = pad_sequences(data['tr']['q1_sequences'], maxlen=MAX_SEQUENCE_LENGTH) \n",
    "data['trq2_padseq'] = pad_sequences(data['tr']['q2_sequences'], maxlen=MAX_SEQUENCE_LENGTH) \n",
    "data['teq1_padseq'] = pad_sequences(data['te']['q1_sequences'], maxlen=MAX_SEQUENCE_LENGTH) \n",
    "data['teq2_padseq'] = pad_sequences(data['te']['q2_sequences'], maxlen=MAX_SEQUENCE_LENGTH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4. prepare embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMBEDDING_FILE='data/word_embed.txt'\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "embeddings_index = {} \n",
    "f = open(EMBEDDING_FILE,\"rb\") \n",
    "for line in f: \n",
    "    values = line.split() \n",
    "    word = values[0] \n",
    "    coefs = np.asarray(values[1:], dtype='float32') \n",
    "    embeddings_index[word] = coefs \n",
    "f.close() \n",
    "\n",
    "nb_words = len(word_index)+1\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM)) \n",
    "for word, i in word_index.items(): \n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** prepare training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sample train/validation data\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "trlen = len(data['trq1_padseq'])\n",
    "perm = np.random.permutation(trlen)\n",
    "idx_train = perm[:int(trlen*(1-VALIDATION_SPLIT))] \n",
    "idx_val = perm[int(trlen*(1-VALIDATION_SPLIT)):] \n",
    "\n",
    "data_trainq1=data['trq1_padseq'][idx_train] \n",
    "data_trainq2=data['trq2_padseq'][idx_train] \n",
    "data_valq1=data['trq1_padseq'][idx_val] \n",
    "data_valq2=data['trq2_padseq'][idx_val] \n",
    "\n",
    "labels_train = data['tr']['label'][idx_train] \n",
    "labels_val = data['tr']['label'][idx_val] \n",
    "\n",
    "\n",
    "date_testq1 = data['teq1_padseq']\n",
    "date_testq2 = data['teq2_padseq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "q1_input (InputLayer)           (None, 272)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "q2_input (InputLayer)           (None, 272)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 272, 300)     4764300     q1_input[0][0]                   \n",
      "                                                                 q2_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "q1_lstm (LSTM)                  (None, 272, 300)     721200      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "q2_lstm (LSTM)                  (None, 272, 300)     721200      embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "q1_drop (Dropout)               (None, 272, 300)     0           q1_lstm[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q2_drop (Dropout)               (None, 272, 300)     0           q2_lstm[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 300)          572         q1_drop[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_2 (Attention)         (None, 300)          572         q2_drop[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "q1q2concat (Concatenate)        (None, 600)          0           attention_1[0][0]                \n",
      "                                                                 attention_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Q_dense (Dense)                 (None, 256)          153856      q1q2concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Q_drop (Dropout)                (None, 256)          0           Q_dense[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Q_batchnorm (BatchNormalization (None, 256)          1024        Q_drop[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Q_output (Dense)                (None, 1)            257         Q_batchnorm[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 6,362,981\n",
      "Trainable params: 1,598,169\n",
      "Non-trainable params: 4,764,812\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(input_dim=nb_words, output_dim=300, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False) \n",
    "num_lstm = 300 \n",
    "num_dense = 256 \n",
    "rate_drop_lstm = 0.25 \n",
    "rate_drop_dense = 0.25 \n",
    "act = 'relu' \n",
    "\n",
    "\n",
    "q1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='q1_input') \n",
    "q2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='q2_input') \n",
    "q1_embseq= embedding_layer(q1_input) \n",
    "q2_embseq= embedding_layer(q2_input) \n",
    "\n",
    "lstm_layerq1 = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm,return_sequences=True, name='q1_lstm') \n",
    "q1_lstm = lstm_layerq1(q1_embseq) \n",
    "q1_drop = Dropout(rate_drop_dense, name='q1_drop')(q1_lstm) \n",
    "q1_att = Attention(MAX_SEQUENCE_LENGTH)(q1_drop)\n",
    "\n",
    "lstm_layerq2 = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm,return_sequences=True, name='q2_lstm') \n",
    "q2_lstm = lstm_layerq2(q2_embseq) \n",
    "q2_drop = Dropout(rate_drop_dense, name='q2_drop')(q2_lstm) \n",
    "q2_att = Attention(MAX_SEQUENCE_LENGTH)(q2_drop)\n",
    "\n",
    "q1q2_concat = Concatenate(axis=-1,name='q1q2concat')([q1_att,q2_att])\n",
    "q1q2_concat = Dense(num_dense, activation=act, name='Q_dense')(q1q2_concat) \n",
    "q1q2_concat = Dropout(rate_drop_dense, name='Q_drop')(q1q2_concat) \n",
    "q1q2_concat = BatchNormalization(name='Q_batchnorm')(q1q2_concat) \n",
    "preds = Dense(1, activation='sigmoid', name='Q_output')(q1q2_concat)\n",
    "\n",
    "model = Model(inputs=[q1_input, q2_input],  outputs=preds) \n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "print(model.summary()) \n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAMP model/simple_lstm_glove_vectors_0.25_0.25\n",
      "bst_model_path model/simple_lstm_glove_vectors_0.25_0.25.h5\n",
      "Train on 228947 samples, validate on 25439 samples\n",
      "Epoch 1/50\n",
      "  1024/228947 [..............................] - ETA: 9:00:30 - loss: 0.6942 - acc: 0.5244"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-744cc160df62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_trainq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_trainq2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_valq1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_valq2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#model.load_weights(bst_model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "STAMP = 'model/simple_lstm_glove_vectors_%.2f_%.2f'%(rate_drop_lstm,rate_drop_dense) \n",
    "print('STAMP',STAMP)\n",
    "bst_model_path = STAMP + '.h5' \n",
    "print('bst_model_path',bst_model_path) \n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=5) \n",
    "#model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True) \n",
    "\n",
    "hist = model.fit([data_trainq1, data_trainq2], labels_train, validation_data=([data_valq1,data_valq2], labels_val), epochs=50, batch_size=256, shuffle=True, callbacks=[early_stopping]) \n",
    "\n",
    "#model.load_weights(bst_model_path) \n",
    "bst_val_score = min(hist.history['val_loss']) \n",
    "\n",
    "y_test = model.predict([date_testq1, date_testq2], batch_size=1024, verbose=1) \n",
    "\n",
    "#data['sam'][list_classes] = y_test \n",
    "#data['sam'].to_csv('%.4f_'%(bst_val_score) + STAMP + '.csv', index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(predict_prob):\n",
    "    with open('submission.csv', 'w') as file:\n",
    "        file.write(str('y_pre') + '\\n')\n",
    "        for line in predict_prob:\n",
    "            file.write(str(line) + '\\n')\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2048/172956 [..............................] - ETA: 1:37:49"
     ]
    }
   ],
   "source": [
    "testpred = model.predict([date_testq1, date_testq2], batch_size=1024, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "make_submission(testpred[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
